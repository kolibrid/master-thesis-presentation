<!doctype html>
<html>
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<title>GeneNet VR</title>

		<link rel="stylesheet" href="dist/reset.css">
		<link rel="stylesheet" href="dist/reveal.css">
		<link rel="stylesheet" href="dist/theme/black.css" id="theme">

		<!-- Theme used for syntax highlighted code -->
		<link rel="stylesheet" href="plugin/highlight/monokai.css" id="highlight-theme">
	</head>
	<body>
		<div class="reveal">
			<div class="slides">

				<!-- Intro slide -->
				<section data-background-image="assets/frontpage_bottom.png">
					<img style="width: 45%;" src="/assets/uit_logo.png">
					<p style="font-size: 24px;">Master's thesis presentation:</p>
					<h2>GeneNet VR: Large Biological Networks in Virtual Reality Using Inexpensive Hardware</h2>
					<h5 style="font-weight: normal;">By: Álvaro Martínez Fernández</h5>
				</section>

				<!-- Index -->
				<section data-background-image="assets/frontpage_bottom.png">
					<h2>Index</h2>
					<ol>
						<li>Introduction</li>
						<li>GeneNet VR</li>
						<li>Evaluation</li>
						<li>Conclusions</li>
						<li>Future work</li>
						<li>Questions</li>
					</ol>
				</section>

				<!-- Introduction -->
				<section data-background-image="assets/frontpage_bottom.png">
					<h2>Introduction</h2>
				</section>

				<!-- MIxT example -->
				<section data-background-video="assets/mixt.mp4" data-background-video-loop data-background-opacity="0.9">
					<h3 style="margin-bottom: 0;color:white; background-color: rgba(0, 0, 0, 0.4); text-transform: none;">
						<span>CASE STUDY: <b>MIxT</b></span>
						<br>
						<span style="font-size: 18px;">https://mixt-tumor-stroma.bci.mcgill.ca/network</span>
					</h3>
					<aside class="notes">
						The Matched Interaction Across Tissues (MIxT) is a system developed by UiT and Concordia University for exploring and comparing transcriptional profiles from two or more matched tissues across individuals.
						This system is implemented as a web application and it has a 2-dimensional visualization tool to explore biological networks.
						Gene co-expression networks (GCN) in biology. They are undirected graphs.
						Significant co-expression relationship between 2 nodes
						Clusters for module membership: clusters of genes that have a similar function or involve in a common biological process
					</aside>
				</section>

				<section data-background-image="assets/visualization_biological.png" data-background-opacity="0.15">
					<h3>Biological networks from MIxT</h3>
					<p>2 datasets: blood and biopsy with biological information from BC patients</p>
					<p>Blood dataset (largest one) has 2693 nodes and one of nodes has 1607 edges (max number in both datasets)</p>
				</section>

				<!-- Our solution -->
				<section data-background-video="assets/geneNetVR_reelshow.mp4" data-background-video-loop data-background-opacity="0.9">
					<h3 style="color:white; background-color: rgba(0, 0, 0, 0.4); text-transform: none;"><b>GeneNet VR</b>
						<br>
						<span style="font-size: 18px;">https://github.com/kolibrid/GeneNet-VR</span>
					</h3>
				</section>

				<!-- Evolution network biology -->
				<section data-background-color="white">
					<div style="display:flex; align-items: center;">
						<h3 style="color:black; margin-right: 80px; text-transform: none;">Evolution of the visualization for network biology</h3>

						<div>
							<img data-src="assets/evolution_visualization.png">
							<p data-caption style="color: black; font-size: 16px; margin-top: 0;">Evolution of the visualization of biological networks through history. From more primitive visualization techniques to more advanced (Virtual Reality). Adapted figure from [1]</p>
						</div>
					</div>

					<small style="color: black; font-size: 14px; margin-top: 50px;">[1] Georgios A. Pavlopoulos et al. “Visualizing genome and systems biology: technologies, tools, implementation techniques and trends, past, present and future.” In: GigaScience 4.1 (2015). doi: 10.1186/s13742-015-0077-2.</small>
				</section>

				<!-- Vitual Reality -->
				<section data-background-image="assets/vr.jpeg" data-background-opacity="0.15">
					<h3>Virtual Reality</h3>
					<p>3-dimensional space</p>
					<p>Immersive</p>
					<p>Very interactive</p>
					<p>Advantages in visualization</p>
				</section>

				<!-- Challenges large biological networks -->
				<!-- <section data-background-image="assets/visualization_biological.png" data-background-opacity="0.15">
					<h3>Challenges visualizing large biological networks</h3>
					<ul>
						<li>Information overload</li>
						<li>High dimensionality</li>
						<li>Interconnectivity</li>
					</ul>
					<aside class="notes">
				    Nowadays, it is possible to sequence hundreds of genomes in just a few days with a cost of around $1,000 each
						Vast amounts of data that are produced can result in a problem: data information overload. To solve this, new visualization tools are needed to help examine large volumes of data so that novel patterns in them can be found, which in turn will lead to new scientific discoveries.
				  </aside>
				</section> -->

				<!-- Related work solutions -->
				<section data-background-image="assets/cellexavr.png" data-background-opacity="0.15">
					<h3>Previous work</h3>
					<ul>
						<li><b>BioVR</b>[2]: visual analysis of DNA/RNA protein structures</li>
						<li><b>CellexaVR</b>[3]: visualization of single-cell RNAseq</li>
						<li><b>BigTop</b>[4]: rendering of Manhattan plots in three dimensions</li>
					</ul>

					<div>
						<small style="font-size: 14px; margin-top: 50px;">
							[2] Jimmy F Zhang et al. “BioVR: a platform for virtual reality assisted biological data integration and visualization.” In: (2018). doi: 10.1101/307769<br>
							[3] Oscar Legetth et al. “CellexalVR: A virtual reality platform for the visualisation and analysis of single-cell gene expression data.” In: bioRxiv (2019). doi: 10.1101/329102<br>
							[4] Samuel T. Westreich et al. “BigTop: A Three-Dimensional Virtual Reality tool for GWAS Visualization.” In: (2019). doi: 10.1101/650176
						</small>
					</div>

					<aside class="notes">
				     BioVR is an interactive VR platform built in Unity for integrated visual analysis of DNA/RNA protein structures. Use of hand tracking for the interactions rather than the controllers. Researchers tend to understand data more quickly in VR environments than in conventional 2D and 3D desktop visualization. --------------

						 CellexalVR is a virtual reality environment for the visualization and analysis of single-cell RNAseq experiments that help researchers understand their data.
						 The system is divided into two parts: the first one consists of the VR interface and the second is an R package called cellexalvrR that does back- end calculations.
						 It allows a multi-user mode via the Photon Unity Networking with "Ghost mode", one of the users only interacts, the other observes. -------------

						 BigTop is a visualization framework in VR for the rendering of Manhattan plots in three dimensions
						 BigTop is built in JavaScript with React and A-Frame, for the web browsers. It can also be rendered in any commercially available VR headsets
						 BigTop allows the user to select a node in order to obtain more information
						 To move around the scene in BigTop the user can take steps (in the VR version) or using the arrow keys from the keyboard.
				  </aside>

				</section>

				<!-- Oculus Quest -->
				<section data-background-image="assets/oculus_quest.jpg" data-background-opacity="0.15">
					<h3>Oculus Quest</h3>
					<ul>
						<li>Standalone VR headset</li>
						<li>Hardware limitations</li>
						<li>Affordable price (Oculus Quest 2 is $299)</li>
					</ul>
				</section>

				<!-- Challenges VR -->
				<!-- <section data-background-image="assets/vr.jpeg" data-background-opacity="0.15">
					<h3>Challenges visualizing large biological networks in Virtual Reality</h3>
					<ul>
						<li>Information overload</li>
						<li>Understand scalability limitations</li>
						<li>Performance requirements (72 FPS)</li>
					</ul>
				</section> -->

				<!-- Challenges large biological networks -->
				<section data-background-image="assets/visualization_biological.png" data-background-opacity="0.15">
					<h3>Contributions</h3>
					<ul>
						<li>GeneNet VR: Prototype of a VR application for the Oculus Quest</li>
						<li>Use case using real large biological networks</li>
						<li>Performance and scalability evaluation</li>
						<li>The system achieves 72 FPS and scales well for the used network sizes</li>
						<li>Interviews with research scientists to obtain feedback</li>
						<li>Design and implementation guidelines based on the evaluation results</li>
					</ul>
				</section>

				<section data-background-image="assets/frontpage_bottom.png">
					<h2>GeneNet VR</h2>
				</section>

				<!-- Implementation of GeneNet VR -->
				<section data-background-color="white">
					<div style="display:flex; align-items: center;">
						<h3 style="color:black; margin-right: 80px; text-transform: none;">Implementation of GeneNet VR</h3>
						<div>
							<img data-src="assets/architecture_design.png">
							<p data-caption style="color: black; font-size: 16px; margin-top: 0;">Architecture and design of GeneNet VR.</p>
						</div>
					</div>
				</section>

				<!-- Particle systems to represent the nodes -->
				<section data-background-image="assets/particles.png" data-background-opacity="0.3">
					<h3>Particle system to represent the nodes</h3>
					<ul>
						<li>Native in Unity</li>
						<li>Control over the position of each of the nodes</li>
						<li>Easy to manipulate</li>
						<li>Store the information in hash maps</li>
						<li>Node names and groups from external files</li>
						<li>The positions are calculated in GeneNet VR</li>
					</ul>
				</section>

				<!-- Lines to represent the edges -->
				<section data-background-image="assets/lines.png" data-background-opacity="0.3">
					<h3>Lines to represent the edges</h3>
					<ul>
						<li>Line Renderer component from Unity</li>
						<li>It consists of 2 points in the 3D space</li>
						<li>Data from external file</li>
						<li>Prefab asset</li>
						<li>Added and removed from the scene dynamically</li>
					</ul>
				</section>


				<!-- Other visual elements -->
				<section data-background-image="assets/genenet_vr.png" data-background-opacity="0.3">
					<h3>Other visual elements</h3>
					<li>Clusters</li>
					<li>Texts for the node names</li>
					<li>2-dimensional menu</li>
				</section>

				<!-- Interactions and controller inputs -->
				<section data-background-color="white">
					<div style="display:flex; align-items: center;">
						<h3 style="color:black; margin-right: 80px; text-transform: none;">Interactions in GeneNet VR</h3>
						<div>
							<img data-src="assets/oculus_quest_inputs.png">
							<p data-caption style="color: black; font-size: 16px; margin-top: 0;">Mapping of the Oculus Quest controllers for the different actions imple- mented in GeneNet VR.</p>
						</div>
					</div>
				</section>

				<!-- Network translation -->
				<section>
					<h3>Network translation</h3>
					<li>The user can move the network with the right controller</li>
					<li>Have control over the position of the network</li>
					<li>Visualize the network from above or below</li>
				</section>

				<!-- Network translation -->
				<section data-background-color="white">
					<div style="display:flex; align-items: center;">
						<h3 style="color:black; margin-right: 80px; text-transform: none;">Network translation</h3>
						<div>
							<video data-autoplay src="assets/translate_network.mp4" loop></video>
							<p data-caption style="color: black; font-size: 16px; margin-top: 0;">Example of the network translation interaction in GeneNet VR.</p>
						</div>
					</div>
				</section>

				<!-- Network scaling -->
				<section data-background-color="white">
					<div style="display:flex; align-items: center;">
						<h3 style="color:black; margin-right: 80px; text-transform: none;">Network scaling</h3>
						<div>
							<video data-autoplay src="assets/network_scale.mp4" loop></video>
							<p data-caption style="color: black; font-size: 16px; margin-top: 0;">Example of the network scaling interaction in GeneNet VR.</p>
						</div>
					</div>
				</section>

				<!-- Node selection -->
				<section>
					<h3>Node selection</h3>
					<li>Select a single node to visualize the edges</li>
					<li>One node at a time</li>
					<li>Laser pointer to select the nodes</li>
				</section>


				<!-- Node selection -->
				<section data-background-color="white">
					<div style="display:flex; align-items: center;">
						<h3 style="color:black; margin-right: 80px; text-transform: none;">Node selection</h3>
						<div>
							<video data-autoplay src="assets/node_selection.mp4" loop></video>
							<p data-caption style="color: black; font-size: 16px; margin-top: 0;">Example of the node selection interaction in GeneNet VR.</p>
						</div>
					</div>
				</section>

				<!-- Locomotion solutions -->
				<section data-background-image="assets/teleportation1.png" data-background-opacity="0.3">
					<h3>Locomotion solutions</h3>
					<li>Teleportation</li>
					<li>Snap rotation</li>
				</section>

				<!-- Node filtering -->
				<section data-background-color="white">
					<div style="display:flex; align-items: center;">
						<h3 style="color:black; margin-right: 80px; text-transform: none;">Node filtering</h3>
						<div>
							<video data-autoplay src="assets/node_filtering.mp4" loop></video>
							<p data-caption style="color: black; font-size: 16px; margin-top: 0;">Example of the node filtering interaction in GeneNet VR.</p>
						</div>
					</div>
				</section>

				<!-- Morphing -->
				<section data-background-image="assets/morph2.png" data-background-opacity="0.3">
					<h3>Network morphing</h3>
					<li>Visualization of 2 networks at the same time</li>
					<li>UI slider to morph from one network to another</li>
					<li>Position and color interpolation</li>
				</section>

				<!-- Morphing -->
				<section data-background-color="white">
					<div style="display:flex; align-items: center;">
						<h3 style="color:black; margin-right: 80px; text-transform: none;">Morphing</h3>
						<div>
							<video data-autoplay src="assets/network_morphing.mp4" loop></video>
							<p data-caption style="color: black; font-size: 16px; margin-top: 0;">Example of the morphing interaction in GeneNet VR.</p>
						</div>
					</div>
				</section>

				<section data-background-image="assets/frontpage_bottom.png">
					<h2>Evaluation</h2>
				</section>

				<!-- Evaluation questions -->
				<section>
						<h3>Evaluation questions</h3>
						<ol>
							<li>For which interactions do we achieve the recommended FPS (72) for large biological networks?</li>
							<li>What network properties influence the scalability?</li>
							<li>Do we achieve the recommended FPS (72) for large biological networks when using the standalone Oculus Quest?</li>
							<li>How do users perceive the visualization of large biological networks in GeneNet VR?</li>
						</ol>
				</section>

				<!-- Benchmark -->
				<section>
						<h3>Benchmark</h3>
						<ul>
							<li>I created repeatable benchmark scripts in Unity</li>
							<li>We repeated the experiments 4 times</li>
							<li>We used the blood dataset from MIxT</li>
							<li>Experiments run on the PC except for one experiment on the Oculus Quest (3rd question)</li>
						</ul>
				</section>

				<!-- Oculus performance guidelines -->
				<section>
						<h3>Oculus' performance guidelines</h3>
						<ul>
							<li>72 FPS for Oculus Quest (required by Oculus)</li>
							<li>50-100 draw calls per frame</li>
							<li>50,000-100,000 triangles or vertices per frame</li>
						</ul>
				</section>

				<!-- 72 FPS -->
				<section>
						<h3>72 FPS</h3>
						<ul>
							<li>We measured the frame time</li>
							<li>The time frame tells you how long each frame takes to render</li>
							<li>The interactions need to be smooth</li>
							<li>13.9 milliseconds is our reference</li>
						</ul>
				</section>

				<!-- Evaluation question 1 -->
				<section>
					<h3>1. For which interactions do we achieve the recommended FPS (72) for large biological networks?</h3>
				</section>

				<!-- Evaluation question 1 -->
				<section>
						<h3>Description of the experiments</h3>
						<ul>
							<li>The experiments were run on the PC's hardware</li>
							<li>Evaluated network translation, network scaling and select node interactions</li>
							<li>Measured the time frame of 700 frames for each experiment</li>
							<li>Used 3 network sizes (whole, half and a third)</li>
							<li>Calculated the average of all the time frames and the average of 1% and 0,25% worst time frames</li>
						</ul>
				</section>

				<section>
						<h3>Description of the experiments</h3>
						<ul>
							<li>Use of sine and linear functions to translate and scale the network experiments</li>
							<li>Edge creation for several nodes in node selection experiment</li>
							<li>Representative averages: all time frames and 1% worst time frames</li>
						</ul>
				</section>

				<!-- Edge distribution -->
				<!-- <section data-background-color="white">
					<div style="display:flex; align-items: center;">
						<h3 style="color:black; margin-right: 80px; text-transform: none;">Edge distribution</h3>
						<div style="width: 60%;">
							<img style="margin-bottom: 0;" data-src="assets/distribution_edges.png">
							<p data-caption style="color: black; font-size: 16px; margin-top: 0;">Cumulative distribution of the number of edges in the blood dataset. etc The x-axis shows the number of edges and the y-axis shows the cumulative distribution.</p>
						</div>
					</div>
				</section> -->

				<!-- Node selection -->
				<!-- <section>
						<h3>Selected nodes</h3>
						<p>TGFBR3 (1), EPSTI1(11), SMNDC1(90), HNRNPH3(290), ANGEL2(586), ACTR6(756), ARGLU1(1607)</p>
				</section> -->

				<!-- Results -->
				<section>
						<h3>Results for the average of all the time frames</h3>
						<p>Translate and scale the network: 6.5 to 6.6 milliseconds</p>
						<p>Select node experiment: 8.6 to 8.7 milliseconds</p>
				</section>

				<!-- Performance summary -->
				<section data-background-color="white">
					<div style="display:flex; align-items: center;">
						<h3 style="color:black; margin-right: 80px; text-transform: none;">Results</h3>
						<div style="width: 60%;">
							<img style="margin-bottom: 0;" data-src="assets/bar_graph_experiments.png">
							<p data-caption style="color: black; font-size: 16px; margin-top: 0;">Bar graph showing a summary of the performance results for the 1% lowest average (7 frames with worst performance).</p>
						</div>
					</div>
				</section>

				<section>
						<h3>Discussion</h3>
						<p>Need to evaluate larger networks</p>
						<p>For which size limits the system performs at 72 FPS?</p>
						<p>The performance for our network sizes meets the 72 FPS</p>
						<p>Performance for node selection is worst</p>
				</section>

				<!-- Evaluation question 2 -->
				<section>
					<h3>2. What network properties influence the scalability?</h3>
				</section>

				<!-- Network properties -->
				<section>
					<h3>Network properties that influence the scalability</h3>
					<li>Number of nodes</li>
					<li>Number of edges</li>
				</section>

				<!-- Scatter plot -->
				<section data-background-color="white">
					<div style="display:flex; align-items: center;">
						<h3 style="color:black; margin-right: 80px; text-transform: none;">Time to create the edges</h3>
						<div style="width: 60%;">
							<img style="margin-bottom: 0;" data-src="assets/number_edges_plot.png">
							<p data-caption style="color: black; font-size: 16px; margin-top: 0;">Scatter plot showing the relation between the number of edges to render and the time that it takes to render for the blood dataset.</p>
						</div>
					</div>
				</section>

				<!-- Discussion -->
				<section>
					<h3>Discussion</h3>
					<li>Hard to determine if the number of edges can have an impact in the scalability</li>
					<li>Need to better isolate the time that it takes to generate the edges</li>
					<li>Use larger networks to evaluate the number of nodes</li>
					<li>Create the edges during the initialization instead of adding them dinamically</li>
				</section>

				<!-- Evaluation question 3 -->
				<section>
					<h3>3. Do we achieve the recommended FPS (72) for large biological networks when using the standalone Oculus Quest?</h3>
				</section>

				<!-- Network properties -->
				<section>
					<h3>Experiment setup</h3>
					<li>Measure time frame for 70 frames</li>
					<li>Experiment run in PC and in the Oculus Quest</li>
					<li>Network translation, network scaling and node selection</li>
				</section>

				<!-- Oculus vs PC -->
				<section data-background-color="white">
					<div style="display:flex; align-items: center;">
						<div>
							<img style="margin-bottom: 0;" data-src="assets/oculus_pc_graph.png">
							<p data-caption style="color: black; font-size: 16px; margin-top: 0;">Performance of GeneNet VR when visualizing the blood dataset running on a machine and on the Oculus Quest. The x-axis represents the frame number (like a timeline). The y-axis represents the amount of time in milliseconds that a particular frame took to render.</p>
						</div>
					</div>
				</section>

				<!-- Discussion -->
				<section>
					<h3>Discussion</h3>
					<li>We achieve the 72 FPS</li>
					<li>When selecting the nodes, the time can increase</li>
					<li>Evaluate bigger networks</li>
					<li>Improve generation of the edges</li>
				</section>

				<!-- Evaluation question 4 -->
				<section>
					<h3>4. How do users perceive the visualization of large biological networks in GeneNet VR?</h3>
				</section>

				<!-- Interview questions -->
				<section>
					<p>6 semi-structured interviews with research scientists</p>
					<p>We asked 3 open-ended questions:</p>
					<ol>
						<li>How do you perceive the application?</li>
						<li>How do you perceive the application for pattern finding?</li>
						<li>What is missing in the application?</li>
					</ol>
				</section>

				<!-- How do you perceive the application? -->
				<section>
					<h3>Discussion</h3>
					<li>GeneNet VR is a helpful visualization tool for large biological networks</li>
					<li>Easy to use and to learn even for novice users in VR</li>
					<li>Good performance and smooth interactions</li>
					<li>The standalone Oculus Quest can be preferred by some users</li>
					<li>Some respondents were interested in visualizing their biology and drug networks</li>
				</section>

				<section>
					<h3>Feedback</h3>
					<li>Show all the interconnected node names</li>
					<li>Possibility to change the network layout</li>
					<li>Search functionality to search for node names</li>
					<li>Possibility to "pin" nodes</li>
					<li>Possibility to use other pathway libraries</li>
					<li>Improve the distance feeling</li>
				</section>

				<!-- Conclusions -->
				<section data-background-image="assets/frontpage_bottom.png">
					<h2>Conclusion</h2>
				</section>

				<!-- Conclusions -->
				<section>
					<h3>Conclusions</h3>
					<li>Prototype of a VR application for the visualization of large biological networks</li>
					<li>Implementation for the Oculus Quest, an inexpensive VR headset</li>
					<li>7-8 milliseconds average for the evaluated interactions (limit is in 13.9 ms)</li>
					<li>Performance around 30% slower on the Oculus Quest, but still meeting the 72 FPS</li>
					<li>Positive feedback from the interviews</li>
				</section>

				<!-- Contributions -->
				<section>
					<h3>Contributions</h3>
					<iframe width="100%" height="500px" autoplay src="https://www.youtube.com/embed/N4QDZiZqVNY" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
					<a href="https://www.youtube.com/watch?v=N4QDZiZqVNY">https://www.youtube.com/watch?v=N4QDZiZqVNY</a>
					<p data-caption style="font-size: 16px; margin-top: 0;">Video contribution of GeneNet VR.</p>
				</section>

				<!-- Contributions -->
				<section>
					<h3>Contributions</h3>
					<img data-src="assets/repository.png">
					<a href="https://github.com/kolibrid/GeneNet-VR">https://github.com/kolibrid/GeneNet-VR</a>
					<p data-caption style="font-size: 16px; margin-top: 0;">Screenshot from the repository on GitHub where GeneNet VR is hosted.</p>
				</section>

				<!-- Future work -->
				<section data-background-image="assets/frontpage_bottom.png">
					<h2>Future work</h2>
				</section>

				<!-- Future work -->
				<section>
					<h3>Future work</h3>
					<li>Issues list in the GitHub repository</li>
					<li>Improve generation of the edges for performance purposes</li>
					<li>Improve the UI elements and representation of the nodes and network</li>
					<li>Highlight the nodes that are selected and the interconnected nodes</li>
					<li>Experiments with larger datasets and for the Oculus Quest</li>
				</section>

				<!-- Future work -->
				<section>
					<h3>New requirements from the interviews</h3>
					<li>Show names of the interconnected nodes</li>
					<li>Show the weight information</li>
					<li>Rotate the network with the controllers</li>
					<li>Build a notebook interface to prepare the datasets</li>
				</section>

				<!-- App future work -->
				<section>
					<h3>Future work</h3>
					<div>
						<img style="width:70%;" data-src="assets/ui_future.png">
						<p data-caption style="font-size: 16px; margin-top: 0;">Design of a UI for GeneNet VR.</p>
					</div>
				</section>

				<!-- Thank you. -->
				<section data-background-image="assets/frontpage_bottom.png">
					<h2>Thank you!</h2>
				</section>

				<!-- Questions? -->
				<section data-background-color="white" data-background-image="assets/frontpage_bottom.png">
					<h2 style="color: white;">Questions?</h2>
				</section>

			</div>
		</div>

		<script src="dist/reveal.js"></script>
		<script src="plugin/notes/notes.js"></script>
		<script src="plugin/markdown/markdown.js"></script>
		<script src="plugin/highlight/highlight.js"></script>
		<script src="plugin/search/search.js"></script>
		<script src="https://code.jquery.com/jquery-3.5.1.min.js"></script>
		<script>
			// More info about initialization & config:
			// - https://revealjs.com/initialization/
			// - https://revealjs.com/config/
			Reveal.initialize({
				hash: true,
				slideNumber: true,

				// Learn about plugins: https://revealjs.com/plugins/
				plugins: [ RevealMarkdown, RevealHighlight, RevealNotes, RevealSearch ]
			});
		</script>
		<script>
			$( document ).ready(function() {
				$("p[data-caption]").each(function(index, value) {
  				let text = $(this).text()
					$(this).text('Figure ' + (index + 1) + ': ' + text)
				});
			});
		</script>
	</body>
</html>
