<!doctype html>
<html>
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<title>GeneNet VR</title>

		<link rel="stylesheet" href="dist/reset.css">
		<link rel="stylesheet" href="dist/reveal.css">
		<link rel="stylesheet" href="dist/theme/black.css" id="theme">

		<!-- Theme used for syntax highlighted code -->
		<link rel="stylesheet" href="plugin/highlight/monokai.css" id="highlight-theme">
	</head>
	<body>
		<div class="reveal">
			<div class="slides">

				<!-- Intro slide -->
				<section data-background-image="assets/frontpage_bottom.png">
					<img style="width: 45%;" src="/assets/uit_logo.png">
					<p style="font-size: 24px;">Master's thesis presentation:</p>
					<h2>GeneNet VR: Large Biological Networks in Virtual Reality Using Inexpensive Hardware</h2>
					<h5 style="font-weight: normal;">By: Álvaro Martínez Fernández</h5>
				</section>

				<!-- Index -->
				<section data-background-image="assets/frontpage_bottom.png">
					<h2>Index</h2>
					<ol>
						<li>Introduction</li>
						<li>GeneNet VR</li>
						<li>Evaluation</li>
						<li>Conclusions</li>
						<li>Future work</li>
						<li>Questions</li>
					</ol>
				</section>

				<!-- Introduction -->
				<section data-background-image="assets/frontpage_bottom.png">
					<h2>Introduction</h2>
				</section>

				<!-- Evolution network biology -->
				<section data-background-color="white">
					<div style="display:flex; align-items: center;">
						<h3 style="color:black; margin-right: 80px; text-transform: none;">Evolution of the visualization for network biology</h3>

						<div>
							<img data-src="assets/evolution_visualization.png">
							<p data-caption style="color: black; font-size: 16px; margin-top: 0;">Evolution of the visualization of biological networks through history. From more primitive visualization techniques to more advanced (Virtual Reality). Adapted figure from [1]</p>
						</div>
					</div>

					<small style="color: black; font-size: 14px; margin-top: 50px;">[1] Georgios A. Pavlopoulos et al. “Visualizing genome and systems biology: technologies, tools, implementation techniques and trends, past, present and future.” In: GigaScience 4.1 (2015). doi: 10.1186/s13742-015-0077-2.</small>
				</section>

				<!-- MIxT example -->
				<section data-background-video="assets/mixt.mp4" data-background-video-loop data-background-opacity="0.9">
					<h3 style="margin-bottom: 0;color:white; background-color: rgba(0, 0, 0, 0.4); text-transform: none;">
						<span>CASE STUDY: <b>MIxT</b></span>
						<br>
						<span style="font-size: 18px;">https://mixt-tumor-stroma.bci.mcgill.ca/network</span>
					</h3>
				</section>

				<!-- Challenges large biological networks -->
				<!-- <section data-background-image="assets/visualization_biological.png" data-background-opacity="0.15">
					<h3>Challenges visualizing large biological networks</h3>
					<ul>
						<li>Information overload</li>
						<li>High dimensionality</li>
						<li>Interconnectivity</li>
					</ul>
					<aside class="notes">
				    Nowadays, it is possible to sequence hundreds of genomes in just a few days with a cost of around $1,000 each
						Vast amounts of data that are produced can result in a problem: data information overload. To solve this, new visualization tools are needed to help examine large volumes of data so that novel patterns in them can be found, which in turn will lead to new scientific discoveries.
				  </aside>
				</section> -->

				<!-- Biological networks -->
				<section data-background-image="assets/visualization_biological.png" data-background-opacity="0.15">
					<h3>Biological networks from MIxT</h3>
					<p><b>Nodes:</b> Genes</p>
					<p><b>Edges:</b> Significant co-expression relationship between 2 nodes</p>
					<p><b>Clusters for module membership:</b> clusters of genes that have a similar function or involve in a common biological process</p>
				</section>

				<section data-background-image="assets/visualization_biological.png" data-background-opacity="0.15">
					<h3>Biological networks from MIxT</h3>
					<p>2 datasets: blood and biopsy with biological information from BC patients</p>
					<p>Blood dataset (largest one) has 2693 nodes and one of nodes has 1607 edges (max number in both datasets)</p>
				</section>

				<!-- Our solution -->
				<section data-background-video="assets/geneNetVR_reelshow.mp4" data-background-video-loop data-background-opacity="0.9">
					<h3 style="color:white; background-color: rgba(0, 0, 0, 0.4); text-transform: none;">Our solution: <b>GeneNet VR</b></h3>
					<aside class="notes">
						The Matched Interaction Across Tissues (MIxT) is a system developed by UiT and Concordia University for exploring and comparing transcriptional profiles from two or more matched tissues across individuals.
						This system is implemented as a web application and it has a 2-dimensional visualization tool to explore biological networks.
						The system has some visualization issues that we focus on improving in our VR protorype.
						The networks from MIxT that we use in our case study are also known as gene co-expression networks (GCN) in biology. They are undirected graphs; meaning that the nodes can be connected together with bidirectional edges. In a GCN, the nodes represent genes and an edge between two nodes represents a significant co-expression relationship.
						3.1, the nodes are in the networks are also organized in clusters and colors. Each cluster corresponds to a module, which is a subgraph where the genes are highly connected and where these genes are part of a common biological process that causes many interactions among themselves.
					</aside>
				</section>

				<!-- Related work solutions -->
				<section data-background-image="assets/visualization_biological.png" data-background-opacity="0.15">
					<h3>Previous work</h3>
					<ul>
						<li>BioVR</li>
						<li>BigTop</li>
						<li>CellexaVR</li>
					</ul>
				</section>

				<!-- Oculus Quest -->
				<section data-background-image="assets/oculus_quest.jpg" data-background-opacity="0.15">
					<h3>Oculus Quest</h3>
					<ul>
						<li>Standalone VR headset</li>
						<li>Hardware limitations</li>
						<li>Affordable price (Oculus Quest 2 is $299)</li>
					</ul>
				</section>

				<!-- Challenges VR -->
				<!-- <section data-background-image="assets/vr.jpeg" data-background-opacity="0.15">
					<h3>Challenges visualizing large biological networks in Virtual Reality</h3>
					<ul>
						<li>Information overload</li>
						<li>Understand scalability limitations</li>
						<li>Performance requirements (72 FPS)</li>
					</ul>
				</section> -->

				<!-- Challenges large biological networks -->
				<section data-background-image="assets/visualization_biological.png" data-background-opacity="0.15">
					<h3>We overcome these problems by providing the following solutions:</h3>
					<ul>
						<li>Visualization system in VR</li>
						<li>Design and implementation guidelines based on the evaluation results</li>
						<li>Implementation for the Oculus Quest</li>
					</ul>
				</section>

				<!-- Methodology -->
				<!-- <section>
					<h3>Methodology</h3>
					<ol>
						<li>Built a prototype of a VR application</li>
						<li>Evaluated scalability performance aspects</li>
						<li>Interviews with researchers to obtain feedback</li>
					</ol>
				</section> -->

				<!-- Thesis statement -->
				<!-- <section>
					<h3>Thesis statement</h3>
					<p>Virtual Reality is advantageous for the visualization of large biological networks and for rapid exploration of patterns in them using affordable hardware</p>
				</section> -->

				<section data-background-image="assets/frontpage_bottom.png">
					<h2>GeneNet VR</h2>
				</section>

				<!-- Implementation of GeneNet VR -->
				<section data-background-color="white">
					<div style="display:flex; align-items: center;">
						<h3 style="color:black; margin-right: 80px; text-transform: none;">Implementation of GeneNet VR</h3>
						<img style="width: 60%;" data-src="assets/architecture_design.png">
					</div>
				</section>

				<!-- Creation of the network -->
				<!-- <section data-background-image="assets/lines.png" data-background-opacity="0.3">
					<h3>Creation of the network</h3>
					<ul>
						<li>Use of external CSV files</li>
						<li>Store the nodes and relationships in hash maps data structures</li>
						<li>Particle system to represent the nodes</li>
					</ul>
				</section> -->

				<!-- Particle systems to represent the nodes -->
				<section data-background-image="assets/particles.png" data-background-opacity="0.3">
					<h3>Particle system to represent the nodes</h3>
					<ul>
						<li>Native in Unity</li>
						<li>Control over the position of each of the nodes</li>
						<li>Easy to manipulate</li>
						<li>Store the information in hash maps</li>
						<li>Node names and groups from external files</li>
						<li>The positions are calculated in GeneNet VR</li>
					</ul>
				</section>

				<!-- Lines to represent the edges -->
				<section data-background-image="assets/lines.png" data-background-opacity="0.3">
					<h3>Lines to represent the edges</h3>
					<ul>
						<li>Line Renderer component from Unity</li>
						<li>It consists of 2 points in the 3D space</li>
						<li>Data from external file</li>
						<li>Prefab asset</li>
						<li>Added and removed from the scene dynamically</li>
					</ul>
				</section>

				<!-- Clusters -->
				<!-- <section data-background-image="assets/clusters.png" data-background-opacity="0.3">
					<h3>Representation of clusters</h3>
					<ul>
						<li>Genes that are significally co-expressed</li>
						<li>The algorithm is applied when the networks are being initialized</li>
					</ul>
				</section> -->

				<!-- Other visual elements -->
				<section data-background-image="assets/genenet_vr.png" data-background-opacity="0.3">
					<h3>Other visual elements</h3>
					<li>Clusters</li>
					<li>Texts for the node names</li>
					<li>2-dimensional menu</li>
				</section>

				<!-- Interactions and controller inputs -->
				<section data-background-color="white">
					<div style="display:flex; align-items: center;">
						<h3 style="color:black; margin-right: 80px; text-transform: none;">Interactions in GeneNet VR</h3>
						<img style="width: 60%;" data-src="assets/oculus_quest_inputs.png">
					</div>
				</section>

				<!-- Network translation -->
				<section>
					<h3>Network translation</h3>
					<li>The user can move the network with the right controller</li>
					<li>Have control over the position of the network</li>
					<li>Visualize the netwowrk from above or below</li>
				</section>

				<!-- Network translation -->
				<!-- <section data-background-color="white">
					<div style="display:flex; align-items: center;">
						<h3 style="color:black; margin-right: 80px; text-transform: none;">Network translation</h3>
						<img style="width: 80%;" data-src="assets/translation.png">
					</div>
				</section> -->

				<!-- Network translation -->
				<!-- <section data-background-color="white">
					<div style="display:flex; align-items: center;">
						<h3 style="color:black; margin-right: 80px; text-transform: none;">Network translation</h3>
						<img style="width: 80%;" data-src="assets/network_translator.png">
					</div>
				</section> -->

				<!-- Network translation -->
				<section data-background-color="white">
					<div style="display:flex; align-items: center;">
						<h3 style="color:black; margin-right: 80px; text-transform: none;">Network translation</h3>
						<video style="width: 70%;" data-autoplay src="assets/translate_network.mp4" loop></video>
					</div>
				</section>

				<!-- Network scaling -->
				<!-- <section>
					<h3>Network scaling</h3>
					<li>Scale the network up and down</li>
					<li>A zoom in and zoom out effect</li>
				</section> -->

				<!-- Network scaling -->
				<!-- <section data-background-color="white">
					<div style="display:flex; align-items: center;">
						<h3 style="color:black; margin-right: 80px; text-transform: none;">Network scaling</h3>
						<img style="width: 60%;" data-src="assets/scaling.png">
					</div>
				</section> -->

				<!-- Network scaling -->
				<!-- <section data-background-color="white">
					<div style="display:flex; align-items: center;">
						<h3 style="color:black; margin-right: 80px; text-transform: none;">Network scaling</h3>
						<img style="width: 60%;" data-src="assets/network_zoom.png">
					</div>
				</section> -->

				<!-- Network scaling -->
				<section data-background-color="white">
					<div style="display:flex; align-items: center;">
						<h3 style="color:black; margin-right: 80px; text-transform: none;">Network scaling</h3>
						<video style="width: 70%;" data-autoplay src="assets/network_scale.mp4" loop></video>
					</div>
				</section>

				<!-- Node selection -->
				<section>
					<h3>Node selection</h3>
					<li>Select a single node to visualize the edges</li>
					<li>One node at a time</li>
					<li>Laser pointer to select the nodes</li>
				</section>

				<!-- Node selection -->
				<!-- <section data-background-color="white">
					<div style="display:flex; align-items: center;">
						<h3 style="color:black; margin-right: 80px; text-transform: none;">Node selection</h3>
						<img style="width: 60%;" data-src="assets/select_node.png">
					</div>
				</section> -->

				<!-- Node selection -->
				<section data-background-color="white">
					<div style="display:flex; align-items: center;">
						<h3 style="color:black; margin-right: 80px; text-transform: none;">Node selection</h3>
						<video style="width: 70%;" data-autoplay src="assets/node_selection.mp4" loop></video>
					</div>
				</section>

				<!-- Teleportation -->
				<!-- <section data-background-image="assets/teleportation1.png" data-background-opacity="0.3">
					<h3>Teleportation</h3>
					<li>Locomotion solution</li>
					<li>Move around the scene using the controllers</li>
					<li>Solves object occlusion problem</li>
					<li>Black flash transition</li>
				</section> -->

				<!-- Teleportation -->
				<!-- <section data-background-color="white">
					<div style="display:flex; align-items: center;">
						<h3 style="color:black; margin-right: 80px; text-transform: none;">Teleportation</h3>
						<video style="width: 70%;" data-autoplay src="assets/teleportation_1.mp4" loop></video>
					</div>
				</section> -->

				<!-- Snap rotation -->
				<!-- <section data-background-image="assets/teleportation1.png" data-background-opacity="0.3">
					<h3>Snap rotation</h3>
					<li>Locomotion solution</li>
					<li>Rotates the camera 45 degrees to the right or left</li>
					<li>Black flash transition</li>
				</section> -->

				<!-- Snap rotation -->
				<!-- <section data-background-color="white">
					<div style="display:flex; align-items: center;">
						<h3 style="color:black; margin-right: 80px; text-transform: none;">Snap rotation</h3>
						<video style="width: 70%;" data-autoplay src="assets/snap_rotation.mp4" loop></video>
					</div>
				</section> -->

				<!-- Locomotion solutions -->
				<section data-background-image="assets/teleportation1.png" data-background-opacity="0.3">
					<h3>Locomotion solutions</h3>
					<li>Teleportation</li>
					<li>Snap rotation</li>
				</section>

				<!-- Node filtering -->
				<!-- <section>
					<h3>Node filtering</h3>
					<li>2-dimensional menu</li>
					<li>Use of checkboxes to filter</li>
				</section> -->

				<!-- Node filtering -->
				<section data-background-color="white">
					<div style="display:flex; align-items: center;">
						<h3 style="color:black; margin-right: 80px; text-transform: none;">Node filtering</h3>
						<video style="width: 70%;" data-autoplay src="assets/node_filtering.mp4" loop></video>
					</div>
				</section>

				<!-- Morphing -->
				<section data-background-image="assets/morph2.png" data-background-opacity="0.3">
					<h3>Network morphing</h3>
					<li>Visualization of 2 networks at the same time</li>
					<li>UI slider to morph from one network to another</li>
					<li>Position and color interpolation</li>
				</section>

				<!-- Morphing -->
				<section data-background-color="white">
					<div style="display:flex; align-items: center;">
						<h3 style="color:black; margin-right: 80px; text-transform: none;">Morphing</h3>
						<video style="width: 70%;" data-autoplay src="assets/network_morphing.mp4" loop></video>
					</div>
				</section>

				<!-- Morphing -->
				<!-- <section data-background-color="white">
					<div style="display:flex; align-items: center;">
						<h3 style="color:black; margin-right: 80px; text-transform: none;">Network morphing</h3>
						<img style="width: 60%;" data-src="assets/network_morph.png">
					</div>
				</section> -->

				<section data-background-image="assets/frontpage_bottom.png">
					<h2>Evaluation</h2>
				</section>

				<!-- Evaluation questions -->
				<section>
						<h3>Evaluation questions</h3>
						<ol>
							<li>For which interactions do we achieve the recommended FPS (72) for large biological networks?</li>
							<li>What network properties influence the scalability?</li>
							<li>Do we achieve the recommended FPS (72) for large biological networks when using the standalone Oculus Quest?</li>
							<li>How do users perceive the visualization of large biological networks in GeneNet VR?</li>
						</ol>
				</section>

				<!-- Benchmark -->
				<section>
						<h3>Benchmark</h3>
						<ul>
							<li>I created repeatable benchmark scripts in Unity</li>
							<li>We repeated the experiments 4 times</li>
							<li>We used the blood dataset from MIxT</li>
							<li>Experiments run on the PC except for one experiment on the Oculus Quest (3rd question)</li>
						</ul>
				</section>

				<!-- Oculus performance guidelines -->
				<section>
						<h3>Oculus' performance guidelines</h3>
						<ul>
							<li>72 FPS for Oculus Quest (required by Oculus)</li>
							<li>50-100 draw calls per frame</li>
							<li>50,000-100,000 triangles or vertices per frame</li>
						</ul>
				</section>

				<!-- 72 FPS -->
				<section>
						<h3>72 FPS</h3>
						<ul>
							<li>We measured the frame time</li>
							<li>Frametime tells you how long each frame takes to render</li>
							<li>The interactions need to be smooth</li>
							<li>13.9 milliseconds is our reference</li>
						</ul>
				</section>

				<!-- Evaluation question 1 -->
				<section>
					<h3>1. For which interactions do we achieve the recommended FPS (72) for large biological networks?</h3>
				</section>

				<!-- Evaluation question 1 -->
				<section>
						<h3>Description of the experiments</h3>
						<ul>
							<li>The experiments were run on the PC's hardware</li>
							<li>Evaluated network translation, network scaling and select node interactions</li>
							<li>Measured the time frame of 700 frames for each experiment</li>
							<li>Used 3 network sizes (whole, half and a third)</li>
							<li>Ccalculated the average of all the time frames and the average of 1% and 0,25% worst time frames</li>
						</ul>
				</section>

				<section>
						<h3>Description of the experiments</h3>
						<ul>
							<li>Use of sine and linear functions to translate and scale the network experiments</li>
							<li>Edge creation for several nodes in node selection experiment</li>
							<li>Representative averages: all time frames and 1% worst time frames</li>
						</ul>
				</section>

				<!-- Translating the network -->
				<!-- <section>
						<h3>Translating the network experiment</h3>
						<ul>
							<li>The network is moved around in the scene</li>
							<li>Sine function in the y-axis</li>
							<li>Linear function in the z-axis</li>
						</ul>
				</section> -->

				<!-- Translating the network meets the 72 FPS -->
				<!-- <section>
						<h3>Translating the network meets the 72 FPS</h3>
						<table style="font-size: 36px;">
							<thead>
								<tr>
									<th>Data size</th>
									<th>0.25% avg. low</th>
									<th>1% avg. low</th>
									<th>Average</th>
								</tr>
							</thead>
							<tbody>
								<tr>
									<th>size</th>
									<th>20.1</th>
									<th>12.2</th>
									<th>6.6</th>
								</tr>
								<tr>
									<th>size/2</th>
									<th>22</th>
									<th>12.8</th>
									<th>6.5</th>
								</tr>
								<tr>
									<th>size/3</th>
									<th>23.3</th>
									<th>13.5</th>
									<th>6.5</th>
								</tr>
							</tbody>
						</table>
						<p style="color: white; font-size: 24px;">Table 1. Performance results in milliseconds when translating the network.</p>
				</section> -->

				<!-- Scaling the network -->
				<!-- <section>
						<h3>Scaling the network experiment</h3>
						<ul>
							<li>The network is scaled up and down</li>
							<li>Sine function to update the size of the network</li>
						</ul>
				</section> -->

				<!-- Scaling the network meets the 72 FPS -->
				<!-- <section>
						<h3>Scaling the network meets the 72 FPS</h3>
						<table style="font-size: 36px;">
							<thead>
								<tr>
									<th>Data size</th>
									<th>0.25% avg. low</th>
									<th>1% avg. low</th>
									<th>Average</th>
								</tr>
							</thead>
							<tbody>
								<tr>
									<th>size</th>
									<th>22.8</th>
									<th>13.4</th>
									<th>6.5</th>
								</tr>
								<tr>
									<th>size/2</th>
									<th>22.6</th>
									<th>12.7</th>
									<th>6.5</th>
								</tr>
								<tr>
									<th>size/3</th>
									<th>23</th>
									<th>13.6</th>
									<th>6.5</th>
								</tr>
							</tbody>
						</table>
						<p style="color: white; font-size: 24px;">Table 2. Performance results in milliseconds for the scale the network interaction.</p>
				</section> -->

				<!-- Node selection -->
				<!-- <section>
						<h3>Node selection experiment</h3>
						<ul>
							<li>We select 7 nodes every 100 frames</li>
							<li>Each node can have a different number of edges to generate</li>
							<li>We just measure the time to generate the edges</li>
						</ul>
				</section> -->

				<!-- Edge distribution -->
				<section data-background-color="white">
					<div style="display:flex; align-items: center;">
						<h3 style="color:black; margin-right: 80px; text-transform: none;">Edge distribution</h3>
						<div style="width: 60%;">
							<img style="margin-bottom: 0;" data-src="assets/distribution_edges.png">
							<p data-caption style="color: black; font-size: 16px; margin-top: 0;">Cumulative distribution of the number of edges in the blood dataset. etc The x-axis shows the number of edges and the y-axis shows the cumulative distribution.</p>
						</div>
					</div>
				</section>

				<!-- Node selection -->
				<section>
						<h3>Selected nodes</h3>
						<p>TGFBR3 (1), EPSTI1(11), SMNDC1(90), HNRNPH3(290), ANGEL2(586), ACTR6(756), ARGLU1(1607)</p>
				</section>

				<!-- Selecting nodes the network meets the 72 FPS -->
				<!-- <section>
						<h3>Selecting nodes the network meets the 72 FPS</h3>
						<table style="font-size: 36px;">
							<thead>
								<tr>
									<th>Data size</th>
									<th>0.25% avg. low</th>
									<th>1% avg. low</th>
									<th>Average</th>
								</tr>
							</thead>
							<tbody>
								<tr>
									<th>size</th>
									<th>100</th>
									<th>65.6</th>
									<th>8.7</th>
								</tr>
								<tr>
									<th>size/2</th>
									<th>100</th>
									<th>56.4</th>
									<th>8.6</th>
								</tr>
								<tr>
									<th>size/3</th>
									<th>100</th>
									<th>56.4</th>
									<th>8.6</th>
								</tr>
							</tbody>
						</table>
						<p style="color: white; font-size: 24px;">Table 3. Performance results in milliseconds for the select node interaction.</p>
				</section> -->

				<!-- Results -->
				<section>
						<h3>Results for the average of all the time frames</h3>
						<p>Translate and scale the network: 6.5 to 6.6 milliseconds</p>
						<p>Select node experiment: 8.6 to 8.7 milliseconds</p>
				</section>

				<!-- Performance summary -->
				<section data-background-color="white">
					<div style="display:flex; align-items: center;">
						<h3 style="color:black; margin-right: 80px; text-transform: none;">Results</h3>
						<div style="width: 60%;">
							<img style="margin-bottom: 0;" data-src="assets/bar_graph_experiments.png">
							<p data-caption style="color: black; font-size: 16px; margin-top: 0;">Bar graph showing a summary of the performance results for the 1% lowest average (7 frames with worst performance).</p>
						</div>
					</div>
				</section>

				<section>
						<h3>Discussion</h3>
						<p>Need to evaluate larger networks</p>
						<p>For which size limits the system performs at 72 FPS?</p>
						<p>The performance for our network sizes meets the 72 FPS</p>
						<p>Performance for node selection is worst</p>
				</section>

				<!-- Evaluation question 2 -->
				<section>
					<h3>2. What network properties influence the scalability?</h3>
				</section>

				<!-- Network properties -->
				<section>
					<h3>Network properties that influence the scalability</h3>
					<li>Number of nodes</li>
					<li>Number of edges</li>
				</section>

				<!-- Scatter plot -->
				<section data-background-color="white">
					<div style="display:flex; align-items: center;">
						<h3 style="color:black; margin-right: 80px; text-transform: none;">Time to create the edges</h3>
						<div style="width: 60%;">
							<img style="margin-bottom: 0;" data-src="assets/number_edges_plot.png">
							<p data-caption style="color: black; font-size: 16px; margin-top: 0;">Scatter plot showing the relation between the number of edges to render and the time that it takes to render for the blood dataset.</p>
						</div>
					</div>
				</section>

				<!-- Profiling selection node -->
				<!-- <section data-background-color="white">
					<div style="display:flex; align-items: center;">
						<div>
							<img style="margin-bottom: 0;" data-src="assets/profiler.png">
							<p data-caption style="color: black; font-size: 16px; margin-top: 0;">Profiling the selection of the node ARGLU1(1607), which has the highest number of edges.</p>
						</div>
					</div>
				</section> -->

				<!-- Triangles profiler -->
				<!-- <section data-background-color="white">
					<div style="display:flex; align-items: center;">
						<div>
							<img style="margin-bottom: 0;" data-src="assets/triangles_profiler.png">
							<p data-caption style="color: black; font-size: 16px; margin-top: 0;">35.2 thousand triangles in the scene when selecting the node ARGLU1, which has 1607 edges, the largest number in the blood dataset.</p>
						</div>
					</div>
				</section> -->

				<!-- Discussion -->
				<section>
					<h3>Discussion</h3>
					<li>Hard to determine if the number of edges can have an impact in the scalability</li>
					<li>Need to better isolate the time that it takes to generate the edges</li>
					<li>Use larger networks to evaluate the number of nodes</li>
					<li>Create the edges during the initialization instead of adding them dinamically</li>
				</section>

				<!-- Evaluation question 3 -->
				<section>
					<h3>3. Do we achieve the recommended FPS (72) for large biological networks when using the standalone Oculus Quest?</h3>
				</section>

				<!-- Network properties -->
				<section>
					<h3>Experiment setup</h3>
					<li>Measure time frame for 70 frames</li>
					<li>Experiment run in PC and in the Oculus Quest</li>
					<li>Network translation, network scaling and node selection</li>
				</section>

				<!-- Oculus vs PC -->
				<section data-background-color="white">
					<div style="display:flex; align-items: center;">
						<div>
							<img style="margin-bottom: 0;" data-src="assets/oculus_pc_graph.png">
							<p data-caption style="color: black; font-size: 16px; margin-top: 0;">Performance of GeneNet VR when visualizing the blood dataset running on a machine and on the Oculus Quest. The x-axis represents the frame number (like a timeline). The y-axis represents the amount of time in milliseconds that a particular frame took to render.</p>
						</div>
					</div>
				</section>

				<!-- Discussion -->
				<section>
					<h3>Discussion</h3>
					<li>We achieve the 72 FPS</li>
					<li>When selecting the nodes, the time can increase</li>
					<li>Evaluate bigger networks</li>
					<li>Improve generation of the edges</li>
				</section>

				<!-- Evaluation question 4 -->
				<section>
					<h3>4. How do users perceive the visualization of large biological networks in GeneNet VR?</h3>
				</section>

				<!-- Interview questions -->
				<section>
					<p>6 semi-structured interviews with research scientists</p>
					<p>We asked 3 open-ended questions:</p>
					<ol>
						<li>How do you perceive the application?</li>
						<li>How do you perceive the application for pattern finding?</li>
						<li>What is missing in the application?</li>
					</ol>
				</section>

				<!-- Respondents -->
				<!-- <section>
					<table style="font-size: 24px;">
						<thead>
							<tr>
								<th>Respondent</th>
								<th>Research field</th>
								<th>Has used VR before?</th>
							</tr>
						</thead>
						<tbody>
							<tr>
								<th>1</th>
								<th>Computer science and works with social networks</th>
								<th>Owns an HTC Vive and uses on a regular basis</th>
							</tr>
							<tr>
								<th>2</th>
								<th>Clinical pharmacy and phar- macoepidemiology</th>
								<th>Several times to play videogames</th>
							</tr>
							<tr>
								<th>3</th>
								<th>Pharmacoepidemiology. Has worked with drug networks</th>
								<th>Has never used it</th>
							</tr>
							<tr>
								<th>4</th>
								<th>Biology. Has worked with gene co-expression networks</th>
								<th>Has used it very little</th>
							</tr>
							<tr>
								<th>5</th>
								<th>Biology. Has worked with gene expression analysis</th>
								<th>Has never used it</th>
							</tr>
							<tr>
								<th>6</th>
								<th>Biology. Has worked with GCN and biological networks</th>
								<th>Has never used it</th>
							</tr>
						</tbody>
					</table>
					<p style="color: white; font-size: 24px;">Table 4. Information about the respondents.</p>
				</section> -->

				<!-- How do you perceive the application? -->
				<!-- <section>
					<h3>1. How do you perceive the application?</h3>
					<li>GeneNet VR shows some advantages for the visualization of large biological networks.</li>
					<li>Respondents 4, 5, and 6 highlighted that the interactions are intuitive and easy to learn.</li>
					<li>No performance issues</li>
					<li>Improve generation of the edges</li>
				</section> -->

				<!-- How do you perceive the application? -->
				<!-- <section>
					<h3>2. How do you perceive the application for pattern finding?</h3>
				</section> -->

				<!-- How do you perceive the application? -->
				<!-- <section>
					<h3>3. What is missing in the application?</h3>
				</section> -->

				<!-- How do you perceive the application? -->
				<section>
					<h3>Discussion</h3>
					<li>GeneNet VR is a helpful visualization tool for large biological networks</li>
					<li>Easy to use and to learn even for novice users in VR</li>
					<li>Good performance and smooth interactions</li>
					<li>The standalone Oculus Quest can be preferred by some users</li>
					<li>Some respondents were interested in visualizing their biology and drug networks</li>
				</section>

				<section>
					<h3>Feedback</h3>
					<li>Show all the interconnected node names</li>
					<li>Possibility to change the network layout</li>
					<li>Search functionality to search for node names</li>
					<li>Possibility to "pin" nodes</li>
					<li>Possibility to use other pathway libraries</li>
					<li>Improve the distance feeling</li>
				</section>

				<!-- Related work -->
				<!-- <section data-background-image="assets/frontpage_bottom.png">
					<h2>Related work</h2>
				</section> -->

				<!-- Virtual Reality Chemical Space -->
				<!-- <section data-background-color="white">
					<div style="display:flex; align-items: center;">
						<h3 style="color:black; margin-right: 20px; text-transform: none;">Virtual Reality Chemical Space</h3>
						<div>
							<img style="margin-bottom: 0;" data-src="assets/drugbank.png">
							<p data-caption style="color: black; font-size: 16px; margin-top: 0;">Screenshot from Virtual Reality Chemical Space.</p>
						</div>
					</div>
					<aside class="notes">
				     VR application for the interactive exploration of chemical space populated by Drugbank compounds.
						 Developed in Unity using C# and the VRTK library.
						 They use a particle system to render the particles of the chemical space.
						 In order to reduce motion sickness, they have introduced a floor in the form of a grid acting as a static frame of reference.
						 Drawback that they found: VR headsets are not so comfortable as well as often-occurring eye strain and virtual reality sickness.
						 They also conclude that the application of VR in chemistry has more potential in the fields of education and training than for the current state of technology.
						 The tools for chemistry need to be further evaluated whether they should be extended to VR.
				  </aside>
				</section> -->

				<!-- BioVR -->
				<!-- <section data-background-color="white">
					<div style="display:flex; align-items: center;">
						<h3 style="color:black; margin-right: 20px; text-transform: none;">BioVR</h3>
						<div>
							<img style="margin-bottom: 0;" data-src="assets/biovr.png">
							<p data-caption style="color: black; font-size: 16px; margin-top: 0;">Screenshot from BioVR.</p>
						</div>
					</div>
					<aside class="notes">
				     BioVR is an interactive VR platform for integrated visual analysis of DNA/RNA protein structures
						 It is built in Unity and using C#.
						 BioVR they use the hands for the interactions rather than the controllers. This can be very attractive and it could have worked very well for GeneNet VR.
				  </aside>
				</section> -->

				<!-- BioVR -->
				<!-- <section data-background-color="white">
					<div style="display:flex; align-items: center;">
						<h3 style="color:black; margin-right: 20px; text-transform: none;">CellexaVR</h3>
						<div>
							<img style="margin-bottom: 0;" data-src="assets/cellexavr.png">
							<p data-caption style="color: black; font-size: 16px; margin-top: 0;">Screenshot from CellexaVR. Two users using CellexalVR at the same time. The head models were taken from NASA.</p>
						</div>
					</div>
					<aside class="notes">
				     CellexalVR is a virtual reality environment for the visualization and analy- sis of single-cell RNAseq experiments that help researchers understand their data.
						 The system is divided into two parts: the first one consists of the VR interface and the second is an R package called cellexalvrR that does back- end calculations.
						 It allows a multi-user mode via the Photon Unity Networking.
						 "Ghost mode", one of the users only interacts, the other observes.
				  </aside>
				</section> -->

				<!-- bigTop -->
				<!-- <section data-background-color="white">
					<div style="display:flex; align-items: center;">
						<h3 style="color:black; margin-right: 20px; text-transform: none;">BigTop</h3>
						<div>
							<img style="margin-bottom: 0;" data-src="assets/bigtop.png">
							<p data-caption style="color: black; font-size: 16px; margin-top: 0;">Screenshot from BigTop where a node is selected.</p>
						</div>
					</div>
					<aside class="notes">
				     BigTop is a visualization framework in VR for the rendering of Manhattan plots in three dimensions
						 BigTop is built in JavaScript with React and A-Frame, for the web browsers. It can also be rendered in any commercially available VR headsets
						 BigTop allows the user to select a node in order to obtain more information
						 To move around the scene in BigTop the user can take steps (in the VR version) or using the arrow keys from the keyboard.
						 In BigNet VR we implement more complex locomotion and interaction techniques. Also we visualize networks, which also have edges.
				  </aside>
				</section> -->

				<!-- Conclusions -->
				<section data-background-image="assets/frontpage_bottom.png">
					<h2>Conclusion</h2>
				</section>

				<!-- Conclusions -->
				<section>
					<h3>Conclusions</h3>
					<li>Prototype of a VR application for the visualization of large biological networks</li>
					<li>Implementation for the Oculus Quest, an inexpensive VR headset</li>
					<li>7-8 milliseconds average for the evaluated interactions (limit is in 13.9 ms)</li>
					<li>Performance around 30% slower on the Oculus Quest, but still meeting the 72 FPS</li>
					<li>Positive feedback from the interviews</li>
				</section>

				<!-- Contributions -->
				<section>
					<h3>Contributions</h3>
					<iframe width="100%" height="500px" autoplay src="https://www.youtube.com/embed/N4QDZiZqVNY" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
					<a href="https://www.youtube.com/watch?v=N4QDZiZqVNY">https://www.youtube.com/watch?v=N4QDZiZqVNY</a>
				</section>

				<!-- Contributions -->
				<section>
					<h3>Contributions</h3>
					<img data-src="assets/repository.png">
					<a href="https://github.com/kolibrid/GeneNet-VR">https://github.com/kolibrid/GeneNet-VR</a>
				</section>

				<!-- Future work -->
				<section data-background-image="assets/frontpage_bottom.png">
					<h2>Future work</h2>
				</section>

				<!-- Future work -->
				<section>
					<h3>Future work</h3>
					<li>Issues list in the GitHub repository</li>
					<li>Improve generation of the edges for performance purposes</li>
					<li>Improve the UI elements and representation of the nodes and network</li>
					<li>Highlight the nodes that are selected and the interconnected nodes</li>
					<li>Experiments with larger datasets and for the Oculus Quest</li>
				</section>

				<!-- Future work -->
				<section>
					<h3>New requirements from the interviews</h3>
					<li>Show names of the interconnected nodes</li>
					<li>Show the weight information</li>
					<li>Rotate the network with the controllers</li>
					<li>Build a notebook interface to prepare the datasets</li>
				</section>

				<!-- App future work -->
				<section>
					<h3>Future work</h3>
					<img data-src="assets/ui_future.png">
				</section>

				<!-- Thank you. -->
				<section data-background-image="assets/frontpage_bottom.png">
					<h2>Thank you!</h2>
				</section>

				<!-- Questions? -->
				<section data-background-color="white" data-background-image="assets/frontpage_bottom.png">
					<h2 style="color: white;">Questions?</h2>
				</section>

			</div>
		</div>

		<script src="dist/reveal.js"></script>
		<script src="plugin/notes/notes.js"></script>
		<script src="plugin/markdown/markdown.js"></script>
		<script src="plugin/highlight/highlight.js"></script>
		<script src="plugin/search/search.js"></script>
		<script src="https://code.jquery.com/jquery-3.5.1.min.js"></script>
		<script>
			// More info about initialization & config:
			// - https://revealjs.com/initialization/
			// - https://revealjs.com/config/
			Reveal.initialize({
				hash: true,
				slideNumber: true,

				// Learn about plugins: https://revealjs.com/plugins/
				plugins: [ RevealMarkdown, RevealHighlight, RevealNotes, RevealSearch ]
			});
		</script>
		<script>
			$( document ).ready(function() {
				$("p[data-caption]").each(function(index, value) {
  				let text = $(this).text()
					$(this).text('Figure ' + (index + 1) + ': ' + text)
				});
			});
		</script>
	</body>
</html>
